{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gnomix Demo\n",
    "\n",
    "This notebook takes you through the process of using the tool for local ancestry predictions both by training a model using your own reference panel and by using a pre-trained model. It then gives an example of how one might analyze the results.\n",
    "\n",
    "The sequencing data we'll be using is from chromosome 22 from the [1000 genomes project](ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gnomix --upgrade\n",
    "!sh download_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the file has been downloaded, we can split the single ancestry samples into a reference panel (training data) and a query panel (test data) for the purpose of this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnomix.generate_dataset_from_1kg import generate_dataset\n",
    "reference_file, reference_sample_map_path, query_file, query_sample_map_path = generate_dataset(name=\"demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize it the distrubution of our ancestries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reference_sample_map = pd.read_csv(reference_sample_map_path, sep=\"\\t\")\n",
    "query_sample_map = pd.read_csv(query_sample_map_path, sep=\"\\t\")\n",
    "\n",
    "sns.histplot(data=reference_sample_map, x=\"Population\", color=\"skyblue\", label=\"Reference\")\n",
    "sns.histplot(data=query_sample_map, x=\"Population\", color=\"red\", label=\"Query\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model from scratch and performing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gnomix.paths import DEMO_DATA_FOLDER, GENETIC_MAP_FOLDER\n",
    "\n",
    "output_basename = DEMO_DATA_FOLDER / \"output\"\n",
    "output_basename.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "should_phase = \"FALSE\"\n",
    "CHR = \"22\"\n",
    "\n",
    "train_and_inference_cmd = \" \".join([\n",
    "    \"python3 run_gnomix.py\",\n",
    "    str(query_file),\n",
    "    str(output_basename),\n",
    "    CHR,\n",
    "    should_phase,\n",
    "    str(GENETIC_MAP_FOLDER / \"allchrs.b37.gmap\"),\n",
    "    str(reference_file),\n",
    "    str(reference_sample_map_path),\n",
    "    f\"> {output_basename}/logs.txt\"\n",
    "])\n",
    "\n",
    "print(\"Running in command line: \\n\\t\", train_and_inference_cmd)\n",
    "status = os.system(train_and_inference_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gnomix.utils import get_window_level_local_ancestry_inference_from_msp_file, get_labels_from_sample_map_file\n",
    "\n",
    "inferred_ancestry_labels = get_window_level_local_ancestry_inference_from_msp_file(path_to_msp_file=output_basename / \"query_results.msp\")\n",
    "true_gloabl_ancestry_labels = get_labels_from_sample_map_file(query_sample_map_path, dtype=inferred_ancestry_labels.dtype)\n",
    "accuracy = np.mean(inferred_ancestry_labels == true_gloabl_ancestry_labels)*100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pre-trained model\n",
    "\n",
    "Let's now see how one can download some of our already trained models and use them for inference.\n",
    "\n",
    "First we'll download the models,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sh download_pretrained_models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run the inference on the same query file as before. This should take around 5 minutes depending on your processors. Biggest part of it is actually just loading the query file and second biggest is writing the inference to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"pretrained_gnomix_models/chr{}/model_chm_{}.pkl\".format(chm, chm)\n",
    "\n",
    "# defining and executing the command\n",
    "run_cmd =  \"python3 gnomix.py\"\n",
    "cmd = \" \".join([run_cmd, query_file, output_basename, chm, phase, path_to_model]) + \\\n",
    "      \" > ./demo/pretrained_log.txt\"\n",
    "\n",
    "print(\"Running in command line: \\n\\t\", cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results\n",
    "\n",
    "### Reading from the ouput\n",
    "\n",
    "Here we read the results from the output file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the output file into a dataframe\n",
    "output_file = output_basename+\"/query_results.msp\"\n",
    "msp_df = pd.read_csv(output_file, sep=\"\\t\", skiprows=[0])\n",
    "msp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from src.visualization import plot_cm, plot_chm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = pd.read_csv(sample_map_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we predict **single ancestry** for each individual by creatoing a dataframe containing only one label prediction for each individual. We do so simply by taking the mode of the local predictions for each individual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the sample-ids\n",
    "query_samples = get_samples_from_msp_df(msp_df)\n",
    "\n",
    "# reading predictions for each of the intervals\n",
    "pred_labels = (np.array(msp_df)[:,6:].T).astype(int)\n",
    "\n",
    "# reducing it to only 1 of maternal/paternal prediction\n",
    "single_ind_idx = np.arange(0,len(query_samples)*2,2)\n",
    "pred_labels_single_ind = pred_labels[single_ind_idx,:]\n",
    "\n",
    "# predicting single ancestry by taking mode of local predictions for each individual\n",
    "y_pred = stats.mode(pred_labels_single_ind,axis=1)[0].squeeze() \n",
    "\n",
    "# get model population order from first line of file and convert from numeric predictions\n",
    "with open(output_file, \"r\") as f:\n",
    "    pop = np.array([p.split(\"=\")[0] for p in f.readline().split()[2:]])\n",
    "pred_pop = [pop[pop_ind] for pop_ind in y_pred]\n",
    "\n",
    "# put it together in dataframe\n",
    "pred_df = pd.DataFrame({\"Sample\": query_samples, \"Prediction\": pred_pop})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the true labels from the sample map file and add them to the dataframe. The true ancestry labels (not only single ancestry individuals) are stored in the meta data file *demo/data/1000g.meta*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the true labels\n",
    "sample_map_file = \"./demo/data/1000g.meta\" # find the true labels in the sample map file\n",
    "sample_map_df = pd.read_csv(sample_map_file, sep=\"\\t\")\n",
    "true_labels_df = sample_map_df[[\"Sample\", \"Superpopulation code\"]]\n",
    "true_labels_df.columns = [\"Sample\", \"Population\"]\n",
    "pred_df = pred_df.merge(true_labels_df)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then compare the predictions with the true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the prediction accuracy\n",
    "acc = np.mean(pred_df.Population == pred_df.Prediction)\n",
    "print(\"Accuracy for single ancestry: \", acc*100, \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and visualizing the confusion matrix\n",
    "labs = np.unique(pred_df[['Population', 'Prediction']])\n",
    "cm = confusion_matrix(pred_df.Population, pred_df.Prediction, labels=labs)\n",
    "cm_plot = plot_cm(cm, normalize=True, labels=labs)\n",
    "cm_plot.figure.savefig('./demo/imgs/single_ancestry_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the prediction\n",
    "\n",
    "We can use the results to plot the predictions along the chromosome. Here is an example of how to use [Tagore](https://pypi.org/project/tagore/#usage) for that purpose. Here we visualize one individual and only for chromosome 22. See **plot_chm** from *src/visualization.py* for more details of how to to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "sample_id = \"HG00096\" # looking at just one random sample\n",
    "img_name = \"./demo/imgs/chm_img\"\n",
    "plot_chm(sample_id, msp_df, img_name=img_name)\n",
    "Image(filename=img_name+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0af29a537668da8e8934f42724ea7fa253eadc68f944a67c43633669224b5089"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gnomix')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
