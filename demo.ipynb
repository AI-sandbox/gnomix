{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gnomix Demo\n",
    "\n",
    "This notebook takes you through the process of using the tool for local ancestry predictions both by training a model using your own reference panel and by using a pre-trained model. It then gives an example of how one might analyze the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "data_path        = \"./demo/data/\"\n",
    "query_file       = data_path + \"ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\"\n",
    "genetic_map_file = data_path + \"allchrs.b37.gmap\"\n",
    "reference_file   = data_path + \"reference_1000g.vcf\"\n",
    "sample_map_file  = data_path + \"1000g.smap\"\n",
    "chm              = \"22\"\n",
    "phase            = \"False\"\n",
    "output_basename  = \"./demo/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model from scratch\n",
    "\n",
    "Here we use the command line interface to train a model using a reference file, make inference on a query file and then write the results to the file *demo.msp.txv*. \n",
    "\n",
    "All the files are stored inside the */demo/data* folder **except for the query file and the reference file**. The query file we'll use is chromosome 22 from the 1000 genomes project which can be downloaded from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/. We'll create the reference file from the query file in the next cell by subsetting the part of the query file that we know are single ancestry samples using the provided sample map (1000g.smap) with bcftools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in command line: \n",
      "\t bcftools view -S ./demo/data/samples_1000g.tsv -o ./demo/data/reference_1000g.vcf ./demo/data/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_map = pd.read_csv(sample_map_file, sep=\"\\t\")\n",
    "samples = list(sample_map[\"#Sample\"])\n",
    "sample_file = data_path + \"samples_1000g.tsv\"\n",
    "np.savetxt(sample_file, samples, delimiter=\"\\t\", fmt=\"%s\")\n",
    "subset_cmd = \"bcftools view\" + \" -S \" + sample_file + \" -o \" + reference_file + \" \" + query_file\n",
    "print(\"Running in command line: \\n\\t\", subset_cmd)\n",
    "os.system(subset_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to train the model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in command line: \n",
      "\t python3 gnomix.py ./demo/data/ALL.chr22.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz ./demo/data/allchrs.b37.gmap ./demo/output 22 False ./demo/data/reference_1000g.vcf ./demo/data/1000g.smap > ./demo/training_log.txt\n"
     ]
    }
   ],
   "source": [
    "train_cmd = \" \".join([\"python3 gnomix.py\",\n",
    "                      query_file, genetic_map_file, output_basename, chm, phase, reference_file, sample_map_file]) + \\\n",
    "            \" > ./demo/training_log.txt\"\n",
    "print(\"Running in command line: \\n\\t\", train_cmd)\n",
    "os.system(train_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pre-trained model\n",
    "\n",
    "The inference has already been done but we can repeat it using the stored model from the training. The model *./demo/model_chm_22.pkl.gz\"* is the same as would be the result of the above process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model    = \"./demo/model_chm_22.pkl.gz\" \n",
    "\n",
    "# defining and executing the command\n",
    "run_cmd =  \"python3 gnomix.py\"\n",
    "cmd = \" \".join([run_cmd, query_file, genetic_map_file, output_basename, chm, phase, path_to_model]) + \\\n",
    "      \" > ./demo/pretrained_log.txt\"\n",
    "print(\"Running in command line: \\n\\t\", cmd)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results\n",
    "\n",
    "### Reading from the ouput\n",
    "\n",
    "Here we read the results from the output file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the output file into a dataframe\n",
    "output_file = output_basename+\"/query_results.msp.tsv\"\n",
    "msp_df = pd.read_csv(output_file, sep=\"\\t\", skiprows=[0])\n",
    "msp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from src.postprocess import get_samples_from_msp_df\n",
    "from src.visualization import plot_cm, plot_chm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_map = pd.read_csv(sample_map_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we predict **single ancestry** for each individual by creatoing a dataframe containing only one label prediction for each individual. We do so simply by taking the mode of the local predictions for each individual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the sample-ids\n",
    "query_samples = get_samples_from_msp_df(msp_df)\n",
    "\n",
    "# reading predictions for each of the intervals\n",
    "pred_labels = (np.array(msp_df)[:,6:].T).astype(int)\n",
    "\n",
    "# reducing it to only 1 of maternal/paternal prediction\n",
    "single_ind_idx = np.arange(0,len(query_samples)*2,2)\n",
    "pred_labels_single_ind = pred_labels[single_ind_idx,:]\n",
    "\n",
    "# predicting single ancestry by taking mode of local predictions for each individual\n",
    "y_pred = stats.mode(pred_labels_single_ind,axis=1)[0].squeeze() \n",
    "\n",
    "# get model population order from first line of file and convert from numeric predictions\n",
    "with open(output_file, \"r\") as f:\n",
    "    pop = np.array([p.split(\"=\")[0] for p in f.readline().split()[2:]])\n",
    "pred_pop = [pop[pop_ind] for pop_ind in y_pred]\n",
    "\n",
    "# put it together in dataframe\n",
    "pred_df = pd.DataFrame({\"Sample\": query_samples, \"Prediction\": pred_pop})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read the true labels from the sample map file and add them to the dataframe. The true ancestry labels (not only single ancestry individuals) are stored in the meta data file *demo/data/1000g.meta*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the true labels\n",
    "sample_map_file = \"./demo/data/1000g.meta\" # find the true labels in the sample map file\n",
    "sample_map_df = pd.read_csv(sample_map_file, sep=\"\\t\")\n",
    "true_labels_df = sample_map_df[[\"Sample\", \"Superpopulation code\"]]\n",
    "true_labels_df.columns = [\"Sample\", \"Population\"]\n",
    "pred_df = pred_df.merge(true_labels_df)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then compare the predictions with the true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the prediction accuracy\n",
    "acc = np.mean(pred_df.Population == pred_df.Prediction)\n",
    "print(\"Accuracy for single ancestry: \", acc*100, \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and visualizing the confusion matrix\n",
    "labs = np.unique(pred_df[['Population', 'Prediction']])\n",
    "cm = confusion_matrix(pred_df.Population, pred_df.Prediction, labels=labs)\n",
    "cm_plot = plot_cm(cm, normalize=True, labels=labs)\n",
    "cm_plot.figure.savefig('./demo/imgs/single_ancestry_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the prediction\n",
    "\n",
    "We can use the results to plot the predictions along the chromosome. Here is an example of how to use [Tagore](https://pypi.org/project/tagore/#usage) for that purpose. Here we visualize one individual and only for chromosome 22. See **plot_chm** from *src/visualization.py* for more details of how to to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "sample_id = \"HG00096\" # looking at just one random sample\n",
    "img_name = \"./demo/imgs/chm_img\"\n",
    "plot_chm(sample_id, msp_df, img_name=img_name)\n",
    "Image(filename=img_name+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
