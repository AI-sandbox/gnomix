{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arvindsk/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "from Benchmarking import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"arvindsk\"\n",
    "# user = \"wknd37\"\n",
    "\n",
    "datasets_benchmark = \"/home/\" + user + \"/xgmix_expts/benchmark_data/val/chm{0}/{1}/{2}/generated_data/\"\n",
    "metrics_benchmark = \"/home/\" + user + \"/xgmix_expts/benchmark_data/val/chm{0}/{1}/{2}/generated_data/chm{0}/\"\n",
    "model_root = \"/home/\" + user + \"/xgmix_expts/benchmark_data/{1}/{2}/{3}/generated_data/chm{0}/all/models/{4}_{5}.pkl\"\n",
    "train_data_root = \"/home/\" + user + \"/xgmix_expts/benchmark_data/{0}/{1}/{2}/generated_data/\"\n",
    "\n",
    "train_gens = [0,2,4,8,16,24,32,48,64,72,100]\n",
    "val_gens = [2,4,8,12,16,20,30,40,50,60,70,80,90,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val data from:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/lgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.67%\n",
      "Base Validation Accuracy: 95.54%\n",
      "Smooth Training Accuracy: 98.47%\n",
      "Smooth Validation Accuracy: 97.55%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.46%\n",
      "Smooth Validation Accuracy: 97.53%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/lgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.9%\n",
      "Base Validation Accuracy: 95.48%\n",
      "Smooth Training Accuracy: 97.87%\n",
      "Smooth Validation Accuracy: 97.39%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.88%\n",
      "Smooth Validation Accuracy: 97.38%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/lgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.67%\n",
      "Base Validation Accuracy: 95.54%\n",
      "Smooth Training Accuracy: 98.37%\n",
      "Smooth Validation Accuracy: 97.45%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.4%\n",
      "Smooth Validation Accuracy: 97.42%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/lgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.9%\n",
      "Base Validation Accuracy: 95.48%\n",
      "Smooth Training Accuracy: 97.83%\n",
      "Smooth Validation Accuracy: 97.28%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.84%\n",
      "Smooth Validation Accuracy: 97.26%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/lgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.67%\n",
      "Base Validation Accuracy: 95.54%\n",
      "Smooth Training Accuracy: 97.62%\n",
      "Smooth Validation Accuracy: 96.77%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.64%\n",
      "Smooth Validation Accuracy: 96.85%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/lgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.9%\n",
      "Base Validation Accuracy: 95.48%\n",
      "Smooth Training Accuracy: 97.07%\n",
      "Smooth Validation Accuracy: 96.76%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.06%\n",
      "Smooth Validation Accuracy: 96.83%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/xgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.69%\n",
      "Base Validation Accuracy: 95.38%\n",
      "Smooth Training Accuracy: 98.5%\n",
      "Smooth Validation Accuracy: 97.46%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.5%\n",
      "Smooth Validation Accuracy: 97.46%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/xgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.85%\n",
      "Base Validation Accuracy: 95.08%\n",
      "Smooth Training Accuracy: 97.92%\n",
      "Smooth Validation Accuracy: 97.3%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.92%\n",
      "Smooth Validation Accuracy: 97.29%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/xgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.69%\n",
      "Base Validation Accuracy: 95.38%\n",
      "Smooth Training Accuracy: 98.53%\n",
      "Smooth Validation Accuracy: 97.39%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.54%\n",
      "Smooth Validation Accuracy: 97.35%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/xgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.85%\n",
      "Base Validation Accuracy: 95.08%\n",
      "Smooth Training Accuracy: 97.93%\n",
      "Smooth Validation Accuracy: 97.28%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.93%\n",
      "Smooth Validation Accuracy: 97.23%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/xgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Training Accuracy:   97.69%\n",
      "Base Validation Accuracy: 95.38%\n",
      "Smooth Training Accuracy: 97.6%\n",
      "Smooth Validation Accuracy: 96.7%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.64%\n",
      "Smooth Validation Accuracy: 96.75%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/xgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.85%\n",
      "Base Validation Accuracy: 95.08%\n",
      "Smooth Training Accuracy: 97.01%\n",
      "Smooth Validation Accuracy: 96.67%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.01%\n",
      "Smooth Validation Accuracy: 96.72%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/logreg_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   99.65%\n",
      "Base Validation Accuracy: 97.52%\n",
      "Smooth Training Accuracy: 99.56%\n",
      "Smooth Validation Accuracy: 98.35%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 99.56%\n",
      "Smooth Validation Accuracy: 98.34%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/logreg_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   99.58%\n",
      "Base Validation Accuracy: 97.6%\n",
      "Smooth Training Accuracy: 99.36%\n",
      "Smooth Validation Accuracy: 98.36%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 99.37%\n",
      "Smooth Validation Accuracy: 98.36%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/logreg_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   99.65%\n",
      "Base Validation Accuracy: 97.52%\n",
      "Smooth Training Accuracy: 99.71%\n",
      "Smooth Validation Accuracy: 98.1%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 99.71%\n",
      "Smooth Validation Accuracy: 98.1%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/logreg_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   99.58%\n",
      "Base Validation Accuracy: 97.62%\n",
      "Smooth Training Accuracy: 99.6%\n",
      "Smooth Validation Accuracy: 98.09%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 99.6%\n",
      "Smooth Validation Accuracy: 98.09%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/logreg_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   99.65%\n",
      "Base Validation Accuracy: 97.53%\n",
      "Smooth Training Accuracy: 98.92%\n",
      "Smooth Validation Accuracy: 97.73%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.95%\n",
      "Smooth Validation Accuracy: 97.83%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/latino/generated_data/chm20/logreg_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   99.58%\n",
      "Base Validation Accuracy: 97.61%\n",
      "Smooth Training Accuracy: 98.87%\n",
      "Smooth Validation Accuracy: 97.9%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.87%\n",
      "Smooth Validation Accuracy: 97.92%\n",
      "Val data from:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/lgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   89.7%\n",
      "Base Validation Accuracy: 85.15%\n",
      "Smooth Training Accuracy: 95.94%\n",
      "Smooth Validation Accuracy: 93.88%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.94%\n",
      "Smooth Validation Accuracy: 93.87%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/lgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   88.5%\n",
      "Base Validation Accuracy: 85.61%\n",
      "Smooth Training Accuracy: 94.71%\n",
      "Smooth Validation Accuracy: 93.55%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.78%\n",
      "Smooth Validation Accuracy: 93.69%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/lgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   89.7%\n",
      "Base Validation Accuracy: 85.15%\n",
      "Smooth Training Accuracy: 95.76%\n",
      "Smooth Validation Accuracy: 93.67%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.79%\n",
      "Smooth Validation Accuracy: 93.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/lgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   88.5%\n",
      "Base Validation Accuracy: 85.61%\n",
      "Smooth Training Accuracy: 94.61%\n",
      "Smooth Validation Accuracy: 93.46%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.61%\n",
      "Smooth Validation Accuracy: 93.36%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/lgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   89.7%\n",
      "Base Validation Accuracy: 85.15%\n",
      "Smooth Training Accuracy: 95.31%\n",
      "Smooth Validation Accuracy: 93.19%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.32%\n",
      "Smooth Validation Accuracy: 93.23%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/lgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   88.5%\n",
      "Base Validation Accuracy: 85.61%\n",
      "Smooth Training Accuracy: 94.2%\n",
      "Smooth Validation Accuracy: 93.2%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.18%\n",
      "Smooth Validation Accuracy: 93.19%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/xgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   88.31%\n",
      "Base Validation Accuracy: 83.66%\n",
      "Smooth Training Accuracy: 95.7%\n",
      "Smooth Validation Accuracy: 93.32%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.7%\n",
      "Smooth Validation Accuracy: 93.32%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/xgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.98%\n",
      "Base Validation Accuracy: 84.11%\n",
      "Smooth Training Accuracy: 94.43%\n",
      "Smooth Validation Accuracy: 93.0%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.5%\n",
      "Smooth Validation Accuracy: 93.16%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/xgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   88.31%\n",
      "Base Validation Accuracy: 83.66%\n",
      "Smooth Training Accuracy: 95.59%\n",
      "Smooth Validation Accuracy: 93.01%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.56%\n",
      "Smooth Validation Accuracy: 93.09%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/xgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.98%\n",
      "Base Validation Accuracy: 84.11%\n",
      "Smooth Training Accuracy: 94.36%\n",
      "Smooth Validation Accuracy: 92.91%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.34%\n",
      "Smooth Validation Accuracy: 92.9%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/xgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   88.31%\n",
      "Base Validation Accuracy: 83.66%\n",
      "Smooth Training Accuracy: 94.92%\n",
      "Smooth Validation Accuracy: 92.55%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.95%\n",
      "Smooth Validation Accuracy: 92.61%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/xgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.98%\n",
      "Base Validation Accuracy: 84.11%\n",
      "Smooth Training Accuracy: 93.77%\n",
      "Smooth Validation Accuracy: 92.64%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.76%\n",
      "Smooth Validation Accuracy: 92.62%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/logreg_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.97%\n",
      "Base Validation Accuracy: 91.64%\n",
      "Smooth Training Accuracy: 98.55%\n",
      "Smooth Validation Accuracy: 96.19%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.56%\n",
      "Smooth Validation Accuracy: 96.18%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/logreg_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.61%\n",
      "Base Validation Accuracy: 91.43%\n",
      "Smooth Training Accuracy: 98.05%\n",
      "Smooth Validation Accuracy: 95.99%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.11%\n",
      "Smooth Validation Accuracy: 96.04%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/logreg_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.97%\n",
      "Base Validation Accuracy: 91.62%\n",
      "Smooth Training Accuracy: 98.84%\n",
      "Smooth Validation Accuracy: 95.33%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.83%\n",
      "Smooth Validation Accuracy: 95.24%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/logreg_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.61%\n",
      "Base Validation Accuracy: 91.43%\n",
      "Smooth Training Accuracy: 98.57%\n",
      "Smooth Validation Accuracy: 95.08%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.55%\n",
      "Smooth Validation Accuracy: 94.97%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/logreg_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.97%\n",
      "Base Validation Accuracy: 91.62%\n",
      "Smooth Training Accuracy: 98.48%\n",
      "Smooth Validation Accuracy: 95.44%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.49%\n",
      "Smooth Validation Accuracy: 95.46%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/five/generated_data/chm20/logreg_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.61%\n",
      "Base Validation Accuracy: 91.43%\n",
      "Smooth Training Accuracy: 98.21%\n",
      "Smooth Validation Accuracy: 95.26%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.21%\n",
      "Smooth Validation Accuracy: 95.28%\n",
      "Val data from:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/lgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   87.86%\n",
      "Base Validation Accuracy: 81.57%\n",
      "Smooth Training Accuracy: 95.32%\n",
      "Smooth Validation Accuracy: 91.97%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.34%\n",
      "Smooth Validation Accuracy: 91.94%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/lgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.49%\n",
      "Base Validation Accuracy: 81.52%\n",
      "Smooth Training Accuracy: 93.27%\n",
      "Smooth Validation Accuracy: 91.27%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.77%\n",
      "Smooth Validation Accuracy: 91.76%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/lgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   87.86%\n",
      "Base Validation Accuracy: 81.57%\n",
      "Smooth Training Accuracy: 95.3%\n",
      "Smooth Validation Accuracy: 91.78%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.31%\n",
      "Smooth Validation Accuracy: 91.52%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/lgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.49%\n",
      "Base Validation Accuracy: 81.52%\n",
      "Smooth Training Accuracy: 94.02%\n",
      "Smooth Validation Accuracy: 91.45%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.98%\n",
      "Smooth Validation Accuracy: 91.31%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/lgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   87.86%\n",
      "Base Validation Accuracy: 81.57%\n",
      "Smooth Training Accuracy: 94.69%\n",
      "Smooth Validation Accuracy: 90.95%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.73%\n",
      "Smooth Validation Accuracy: 91.07%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/lgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.49%\n",
      "Base Validation Accuracy: 81.52%\n",
      "Smooth Training Accuracy: 93.41%\n",
      "Smooth Validation Accuracy: 91.09%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.4%\n",
      "Smooth Validation Accuracy: 91.09%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/xgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.28%\n",
      "Base Validation Accuracy: 80.16%\n",
      "Smooth Training Accuracy: 94.91%\n",
      "Smooth Validation Accuracy: 91.43%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.92%\n",
      "Smooth Validation Accuracy: 91.4%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/xgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   84.77%\n",
      "Base Validation Accuracy: 79.94%\n",
      "Smooth Training Accuracy: 92.82%\n",
      "Smooth Validation Accuracy: 90.65%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.33%\n",
      "Smooth Validation Accuracy: 91.22%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/xgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.28%\n",
      "Base Validation Accuracy: 80.16%\n",
      "Smooth Training Accuracy: 94.91%\n",
      "Smooth Validation Accuracy: 91.19%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.93%\n",
      "Smooth Validation Accuracy: 91.05%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/xgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   84.77%\n",
      "Base Validation Accuracy: 79.94%\n",
      "Smooth Training Accuracy: 93.64%\n",
      "Smooth Validation Accuracy: 90.9%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.64%\n",
      "Smooth Validation Accuracy: 90.81%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/xgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   86.28%\n",
      "Base Validation Accuracy: 80.16%\n",
      "Smooth Training Accuracy: 94.06%\n",
      "Smooth Validation Accuracy: 90.37%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 94.11%\n",
      "Smooth Validation Accuracy: 90.51%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/xgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   84.77%\n",
      "Base Validation Accuracy: 79.94%\n",
      "Smooth Training Accuracy: 92.77%\n",
      "Smooth Validation Accuracy: 90.48%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.77%\n",
      "Smooth Validation Accuracy: 90.48%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/logreg_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.24%\n",
      "Base Validation Accuracy: 88.08%\n",
      "Smooth Training Accuracy: 98.12%\n",
      "Smooth Validation Accuracy: 94.25%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.15%\n",
      "Smooth Validation Accuracy: 94.2%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/logreg_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.74%\n",
      "Base Validation Accuracy: 87.4%\n",
      "Smooth Training Accuracy: 96.86%\n",
      "Smooth Validation Accuracy: 93.77%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.26%\n",
      "Smooth Validation Accuracy: 93.97%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/logreg_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.24%\n",
      "Base Validation Accuracy: 88.1%\n",
      "Smooth Training Accuracy: 98.66%\n",
      "Smooth Validation Accuracy: 92.93%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.63%\n",
      "Smooth Validation Accuracy: 92.8%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/logreg_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.73%\n",
      "Base Validation Accuracy: 87.4%\n",
      "Smooth Training Accuracy: 98.33%\n",
      "Smooth Validation Accuracy: 92.52%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.31%\n",
      "Smooth Validation Accuracy: 92.33%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/logreg_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   97.24%\n",
      "Base Validation Accuracy: 88.08%\n",
      "Smooth Training Accuracy: 98.25%\n",
      "Smooth Validation Accuracy: 93.06%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 98.26%\n",
      "Smooth Validation Accuracy: 93.1%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/full/seven/generated_data/chm20/logreg_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   96.73%\n",
      "Base Validation Accuracy: 87.41%\n",
      "Smooth Training Accuracy: 97.94%\n",
      "Smooth Validation Accuracy: 92.72%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.94%\n",
      "Smooth Validation Accuracy: 92.73%\n",
      "Val data from:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/lgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.67%\n",
      "Base Validation Accuracy: 90.2%\n",
      "Smooth Training Accuracy: 97.03%\n",
      "Smooth Validation Accuracy: 96.03%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.03%\n",
      "Smooth Validation Accuracy: 96.02%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/lgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   90.92%\n",
      "Base Validation Accuracy: 89.87%\n",
      "Smooth Training Accuracy: 95.98%\n",
      "Smooth Validation Accuracy: 96.0%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.99%\n",
      "Smooth Validation Accuracy: 95.97%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/lgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.67%\n",
      "Base Validation Accuracy: 90.2%\n",
      "Smooth Training Accuracy: 96.9%\n",
      "Smooth Validation Accuracy: 96.01%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.98%\n",
      "Smooth Validation Accuracy: 96.11%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/lgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   90.92%\n",
      "Base Validation Accuracy: 89.87%\n",
      "Smooth Training Accuracy: 95.86%\n",
      "Smooth Validation Accuracy: 95.93%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.98%\n",
      "Smooth Validation Accuracy: 95.97%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/lgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.67%\n",
      "Base Validation Accuracy: 90.2%\n",
      "Smooth Training Accuracy: 96.38%\n",
      "Smooth Validation Accuracy: 95.46%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.41%\n",
      "Smooth Validation Accuracy: 95.55%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/lgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   90.92%\n",
      "Base Validation Accuracy: 89.87%\n",
      "Smooth Training Accuracy: 95.41%\n",
      "Smooth Validation Accuracy: 95.49%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.41%\n",
      "Smooth Validation Accuracy: 95.49%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/xgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.45%\n",
      "Base Validation Accuracy: 89.81%\n",
      "Smooth Training Accuracy: 97.0%\n",
      "Smooth Validation Accuracy: 95.93%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.01%\n",
      "Smooth Validation Accuracy: 95.92%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/xgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   90.5%\n",
      "Base Validation Accuracy: 89.32%\n",
      "Smooth Training Accuracy: 96.0%\n",
      "Smooth Validation Accuracy: 95.92%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.01%\n",
      "Smooth Validation Accuracy: 95.89%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/xgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.45%\n",
      "Base Validation Accuracy: 89.81%\n",
      "Smooth Training Accuracy: 96.89%\n",
      "Smooth Validation Accuracy: 95.91%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.96%\n",
      "Smooth Validation Accuracy: 96.01%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/xgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Training Accuracy:   90.5%\n",
      "Base Validation Accuracy: 89.32%\n",
      "Smooth Training Accuracy: 95.9%\n",
      "Smooth Validation Accuracy: 95.81%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.02%\n",
      "Smooth Validation Accuracy: 95.85%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/xgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.45%\n",
      "Base Validation Accuracy: 89.81%\n",
      "Smooth Training Accuracy: 96.21%\n",
      "Smooth Validation Accuracy: 95.19%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.26%\n",
      "Smooth Validation Accuracy: 95.27%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/xgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   90.5%\n",
      "Base Validation Accuracy: 89.32%\n",
      "Smooth Training Accuracy: 95.31%\n",
      "Smooth Validation Accuracy: 95.31%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 95.31%\n",
      "Smooth Validation Accuracy: 95.3%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/logreg_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   94.23%\n",
      "Base Validation Accuracy: 92.26%\n",
      "Smooth Training Accuracy: 97.5%\n",
      "Smooth Validation Accuracy: 96.59%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.49%\n",
      "Smooth Validation Accuracy: 96.59%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/logreg_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.57%\n",
      "Base Validation Accuracy: 91.65%\n",
      "Smooth Training Accuracy: 96.52%\n",
      "Smooth Validation Accuracy: 96.51%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.54%\n",
      "Smooth Validation Accuracy: 96.49%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/logreg_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   94.23%\n",
      "Base Validation Accuracy: 92.26%\n",
      "Smooth Training Accuracy: 97.35%\n",
      "Smooth Validation Accuracy: 96.46%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.4%\n",
      "Smooth Validation Accuracy: 96.55%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/logreg_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.57%\n",
      "Base Validation Accuracy: 91.65%\n",
      "Smooth Training Accuracy: 96.4%\n",
      "Smooth Validation Accuracy: 96.45%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.44%\n",
      "Smooth Validation Accuracy: 96.47%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/logreg_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   94.23%\n",
      "Base Validation Accuracy: 92.26%\n",
      "Smooth Training Accuracy: 96.98%\n",
      "Smooth Validation Accuracy: 96.12%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 97.01%\n",
      "Smooth Validation Accuracy: 96.18%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/latino/generated_data/chm20/logreg_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   92.57%\n",
      "Base Validation Accuracy: 91.64%\n",
      "Smooth Training Accuracy: 96.05%\n",
      "Smooth Validation Accuracy: 96.11%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 96.06%\n",
      "Smooth Validation Accuracy: 96.13%\n",
      "Val data from:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/lgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   79.3%\n",
      "Base Validation Accuracy: 75.41%\n",
      "Smooth Training Accuracy: 93.07%\n",
      "Smooth Validation Accuracy: 90.14%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.08%\n",
      "Smooth Validation Accuracy: 90.16%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/lgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   75.1%\n",
      "Base Validation Accuracy: 73.73%\n",
      "Smooth Training Accuracy: 91.13%\n",
      "Smooth Validation Accuracy: 89.5%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.27%\n",
      "Smooth Validation Accuracy: 90.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/lgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   79.3%\n",
      "Base Validation Accuracy: 75.41%\n",
      "Smooth Training Accuracy: 92.69%\n",
      "Smooth Validation Accuracy: 89.9%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.94%\n",
      "Smooth Validation Accuracy: 90.08%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/lgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   75.1%\n",
      "Base Validation Accuracy: 73.73%\n",
      "Smooth Training Accuracy: 90.72%\n",
      "Smooth Validation Accuracy: 89.73%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.13%\n",
      "Smooth Validation Accuracy: 89.89%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/lgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   79.3%\n",
      "Base Validation Accuracy: 75.41%\n",
      "Smooth Training Accuracy: 92.45%\n",
      "Smooth Validation Accuracy: 89.66%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.49%\n",
      "Smooth Validation Accuracy: 89.72%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/lgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   75.1%\n",
      "Base Validation Accuracy: 73.73%\n",
      "Smooth Training Accuracy: 90.72%\n",
      "Smooth Validation Accuracy: 89.65%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 90.7%\n",
      "Smooth Validation Accuracy: 89.65%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/xgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   78.08%\n",
      "Base Validation Accuracy: 74.25%\n",
      "Smooth Training Accuracy: 92.6%\n",
      "Smooth Validation Accuracy: 89.38%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.61%\n",
      "Smooth Validation Accuracy: 89.4%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/xgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   73.33%\n",
      "Base Validation Accuracy: 72.08%\n",
      "Smooth Training Accuracy: 90.66%\n",
      "Smooth Validation Accuracy: 88.83%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 90.79%\n",
      "Smooth Validation Accuracy: 89.38%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/xgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   78.08%\n",
      "Base Validation Accuracy: 74.25%\n",
      "Smooth Training Accuracy: 92.23%\n",
      "Smooth Validation Accuracy: 89.26%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.58%\n",
      "Smooth Validation Accuracy: 89.5%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/xgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   73.33%\n",
      "Base Validation Accuracy: 72.08%\n",
      "Smooth Training Accuracy: 90.24%\n",
      "Smooth Validation Accuracy: 89.08%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 90.7%\n",
      "Smooth Validation Accuracy: 89.31%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/xgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   78.08%\n",
      "Base Validation Accuracy: 74.25%\n",
      "Smooth Training Accuracy: 91.9%\n",
      "Smooth Validation Accuracy: 88.91%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.95%\n",
      "Smooth Validation Accuracy: 89.0%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/xgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   73.33%\n",
      "Base Validation Accuracy: 72.08%\n",
      "Smooth Training Accuracy: 90.17%\n",
      "Smooth Validation Accuracy: 89.05%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 90.17%\n",
      "Smooth Validation Accuracy: 89.03%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/logreg_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   80.24%\n",
      "Base Validation Accuracy: 77.09%\n",
      "Smooth Training Accuracy: 93.07%\n",
      "Smooth Validation Accuracy: 90.7%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 93.07%\n",
      "Smooth Validation Accuracy: 90.71%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/logreg_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   74.76%\n",
      "Base Validation Accuracy: 74.49%\n",
      "Smooth Training Accuracy: 90.96%\n",
      "Smooth Validation Accuracy: 90.2%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.03%\n",
      "Smooth Validation Accuracy: 90.52%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/logreg_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   80.24%\n",
      "Base Validation Accuracy: 77.09%\n",
      "Smooth Training Accuracy: 92.65%\n",
      "Smooth Validation Accuracy: 90.51%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.89%\n",
      "Smooth Validation Accuracy: 90.8%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/logreg_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   74.76%\n",
      "Base Validation Accuracy: 74.49%\n",
      "Smooth Training Accuracy: 90.41%\n",
      "Smooth Validation Accuracy: 90.36%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 90.77%\n",
      "Smooth Validation Accuracy: 90.56%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/logreg_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   80.24%\n",
      "Base Validation Accuracy: 77.09%\n",
      "Smooth Training Accuracy: 92.53%\n",
      "Smooth Validation Accuracy: 90.33%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.56%\n",
      "Smooth Validation Accuracy: 90.37%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/five/generated_data/chm20/logreg_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   74.76%\n",
      "Base Validation Accuracy: 74.49%\n",
      "Smooth Training Accuracy: 90.54%\n",
      "Smooth Validation Accuracy: 90.32%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 90.54%\n",
      "Smooth Validation Accuracy: 90.32%\n",
      "Val data from:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/lgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   76.05%\n",
      "Base Validation Accuracy: 71.61%\n",
      "Smooth Training Accuracy: 91.94%\n",
      "Smooth Validation Accuracy: 87.34%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 92.01%\n",
      "Smooth Validation Accuracy: 87.39%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/lgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/lgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   70.48%\n",
      "Base Validation Accuracy: 68.08%\n",
      "Smooth Training Accuracy: 88.69%\n",
      "Smooth Validation Accuracy: 85.77%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 89.39%\n",
      "Smooth Validation Accuracy: 86.98%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/lgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   76.05%\n",
      "Base Validation Accuracy: 71.61%\n",
      "Smooth Training Accuracy: 91.6%\n",
      "Smooth Validation Accuracy: 87.44%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.82%\n",
      "Smooth Validation Accuracy: 87.56%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/lgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/lgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   70.48%\n",
      "Base Validation Accuracy: 68.08%\n",
      "Smooth Training Accuracy: 89.02%\n",
      "Smooth Validation Accuracy: 86.92%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 89.54%\n",
      "Smooth Validation Accuracy: 86.85%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/lgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   76.05%\n",
      "Base Validation Accuracy: 71.61%\n",
      "Smooth Training Accuracy: 91.25%\n",
      "Smooth Validation Accuracy: 86.86%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.29%\n",
      "Smooth Validation Accuracy: 86.93%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/lgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/lgb_cnv.pkl\n",
      "Getting traintime data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   70.48%\n",
      "Base Validation Accuracy: 68.08%\n",
      "Smooth Training Accuracy: 89.06%\n",
      "Smooth Validation Accuracy: 86.76%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 89.05%\n",
      "Smooth Validation Accuracy: 86.75%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/xgb_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   74.81%\n",
      "Base Validation Accuracy: 70.53%\n",
      "Smooth Training Accuracy: 91.21%\n",
      "Smooth Validation Accuracy: 86.48%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.32%\n",
      "Smooth Validation Accuracy: 86.6%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/xgb_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/xgb_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   68.37%\n",
      "Base Validation Accuracy: 66.07%\n",
      "Smooth Training Accuracy: 87.91%\n",
      "Smooth Validation Accuracy: 84.9%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 88.58%\n",
      "Smooth Validation Accuracy: 86.19%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/xgb_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   74.81%\n",
      "Base Validation Accuracy: 70.53%\n",
      "Smooth Training Accuracy: 91.02%\n",
      "Smooth Validation Accuracy: 86.76%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.33%\n",
      "Smooth Validation Accuracy: 86.95%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/xgb_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/xgb_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   68.37%\n",
      "Base Validation Accuracy: 66.07%\n",
      "Smooth Training Accuracy: 88.33%\n",
      "Smooth Validation Accuracy: 86.16%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 88.9%\n",
      "Smooth Validation Accuracy: 86.21%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/xgb_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   74.81%\n",
      "Base Validation Accuracy: 70.53%\n",
      "Smooth Training Accuracy: 90.51%\n",
      "Smooth Validation Accuracy: 86.03%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 90.57%\n",
      "Smooth Validation Accuracy: 86.15%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/xgb_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/xgb_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   68.37%\n",
      "Base Validation Accuracy: 66.07%\n",
      "Smooth Training Accuracy: 88.2%\n",
      "Smooth Validation Accuracy: 86.1%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 88.19%\n",
      "Smooth Validation Accuracy: 86.09%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/logreg_xgb_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   76.22%\n",
      "Base Validation Accuracy: 72.86%\n",
      "Smooth Training Accuracy: 91.58%\n",
      "Smooth Validation Accuracy: 87.74%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.65%\n",
      "Smooth Validation Accuracy: 87.81%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/logreg_xgb_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/logreg_xgb.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   68.58%\n",
      "Base Validation Accuracy: 67.9%\n",
      "Smooth Training Accuracy: 88.02%\n",
      "Smooth Validation Accuracy: 86.22%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 88.55%\n",
      "Smooth Validation Accuracy: 87.27%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/logreg_crf_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   76.21%\n",
      "Base Validation Accuracy: 72.87%\n",
      "Smooth Training Accuracy: 91.04%\n",
      "Smooth Validation Accuracy: 87.81%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.45%\n",
      "Smooth Validation Accuracy: 88.02%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/logreg_crf_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/logreg_crf.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   68.58%\n",
      "Base Validation Accuracy: 67.9%\n",
      "Smooth Training Accuracy: 87.81%\n",
      "Smooth Validation Accuracy: 87.14%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 88.38%\n",
      "Smooth Validation Accuracy: 87.4%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/logreg_cnv_unbal_unbal.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   76.22%\n",
      "Base Validation Accuracy: 72.86%\n",
      "Smooth Training Accuracy: 90.96%\n",
      "Smooth Validation Accuracy: 87.38%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 91.0%\n",
      "Smooth Validation Accuracy: 87.43%\n",
      "Metrics will show up at:  /home/arvindsk/xgmix_expts/benchmark_data/val/chm20/ukb/seven/generated_data/chm20/logreg_cnv_bal_admix.benchmark\n",
      "Loading model from:  /home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/generated_data/chm20/all/models/logreg_cnv.pkl\n",
      "Getting traintime data\n",
      "Getting validation set that was separately generated\n",
      "Val generations:  [2, 4, 8, 12, 16, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
      "Base Training Accuracy:   68.58%\n",
      "Base Validation Accuracy: 67.9%\n",
      "Smooth Training Accuracy: 88.14%\n",
      "Smooth Validation Accuracy: 87.09%\n",
      "retrieving accuracies..\n",
      "calculating log loss..\n",
      "retrieving training and inference time..\n",
      "estimating model size..\n",
      "estimating accuracy for each generation..\n",
      "Smooth Training Accuracy: 88.14%\n",
      "Smooth Validation Accuracy: 87.12%\n"
     ]
    }
   ],
   "source": [
    "for set_name in [\"full\",\"ukb\"]:\n",
    "    W = 30 if set_name == \"ukb\" else 1000\n",
    "\n",
    "    for pop_name in [\"latino\",\"five\",\"seven\"]:\n",
    "        \n",
    "        data_path = datasets_benchmark.format(chm,set_name,pop_name)\n",
    "        print(\"Val data from: \",data_path)\n",
    "        \n",
    "\n",
    "        for base in [\"lgb\", \"xgb\", \"logreg\"]:\n",
    "            for smooth in [\"xgb\", \"crf\", \"cnv\"]:\n",
    "                \n",
    "                for bal in [\"unbal_unbal\",\"bal_admix\"]:\n",
    "\n",
    "                    metric_path = os.path.join(metrics_benchmark.format(chm,set_name,pop_name),\"{}_{}_{}.benchmark\".format(base,smooth,bal))\n",
    "                    print(\"Metrics will show up at: \",metric_path)\n",
    "                    metrics = {}\n",
    "\n",
    "                    # load model\n",
    "                    model_path = model_root.format(chm,set_name,bal,pop_name,base,smooth)\n",
    "                    print(\"Loading model from: \",model_path)\n",
    "                    \n",
    "                    # load the original train and val data to get training time metrics\n",
    "                    print(\"Getting traintime data\")\n",
    "                    train_data_path = train_data_root.format(set_name,bal,pop_name)\n",
    "                    data, meta, _ = get_data(train_data_path, W=W, gens=train_gens, chm=chm, verbose=False)\n",
    "                    (X_t1, y_t1), (X_t2, y_t2), (X_v, y_v) = data\n",
    "                    \n",
    "                    print(\"Getting validation set that was separately generated\")\n",
    "                    print(\"Val generations: \",val_gens)\n",
    "                    val_paths = [data_path + \"/chm{}/simulation_output/val/gen_\".format(chm)    + str(gen) + \"/\" for gen in val_gens] \n",
    "                    X_val_files    = [p + \"mat_vcf_2d.npy\" for p in val_paths]\n",
    "                    labels_val_files    = [p + \"mat_map.npy\" for p in val_paths]\n",
    "                    train_val_files = [X_val_files, labels_val_files]\n",
    "                    X_val_raw, labels_val_raw = [load_np_data(f) for f in train_val_files]\n",
    "                    X_val, labels_window_val       = data_process(X_val_raw, labels_val_raw, W, 0)\n",
    "                    val = np.array(X_val).astype(\"int8\")\n",
    "                    val_lab = np.array(labels_window_val).astype(\"int16\")\n",
    "                    \n",
    "                    # glue the old train data with the new val data\n",
    "                    data = ((X_t1,y_t1),(X_t2,y_t2),(val,val_lab))\n",
    "                    y_snp = labels_val_raw.copy()\n",
    "                    \n",
    "                    # here pass on the val_gens since we only pass val set into the accuracy computing functions\n",
    "                    metrics = bm_eval(model_path, data, gens=val_gens, eval_calibration=True, y_snp=y_snp, verbose=verbose)\n",
    "\n",
    "                    save_dict(metrics,metric_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_train_acc': 68.58,\n",
       " 'base_val_acc': 67.9,\n",
       " 'base_train_acc_bal': 67.64,\n",
       " 'base_val_acc_bal': 61.1,\n",
       " 'train_acc': 88.14,\n",
       " 'val_acc': 87.09,\n",
       " 'train_acc_bal': 88.14,\n",
       " 'val_acc_bal': 81.19,\n",
       " 'log_loss': 0.39,\n",
       " 'smooth_training_time': 82.8,\n",
       " 'smooth_inference_time': 0.05,\n",
       " 'training_time': 1190.6699999999998,\n",
       " 'inference_time': 0.29,\n",
       " 'model_total_size_mb': 2.06,\n",
       " 'gen_performance': {'gens': [2,\n",
       "   4,\n",
       "   8,\n",
       "   12,\n",
       "   16,\n",
       "   20,\n",
       "   30,\n",
       "   40,\n",
       "   50,\n",
       "   60,\n",
       "   70,\n",
       "   80,\n",
       "   90,\n",
       "   100],\n",
       "  'accs': [96.65,\n",
       "   96.08,\n",
       "   95.14,\n",
       "   91.96,\n",
       "   93.27,\n",
       "   90.2,\n",
       "   89.11,\n",
       "   86.68,\n",
       "   84.66,\n",
       "   82.05,\n",
       "   80.31,\n",
       "   79.45,\n",
       "   77.75,\n",
       "   75.9],\n",
       "  'accs_snp_lvl': [96.64,\n",
       "   96.06,\n",
       "   95.12,\n",
       "   91.93,\n",
       "   93.21,\n",
       "   90.08,\n",
       "   88.95,\n",
       "   86.52,\n",
       "   84.37,\n",
       "   81.78,\n",
       "   80.03,\n",
       "   79.09,\n",
       "   77.39,\n",
       "   75.54]},\n",
       " 'val_acc_snp_lvl': 86.91,\n",
       " 'val_acc_cal': 87.12,\n",
       " 'val_ll_cal': 0.38641329680434583}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bm(base, smooth, chm, gen_expts, models_exist=False, local_metric=None):\n",
    "\n",
    "    for data_path in datasets_benchmark:\n",
    "\n",
    "        # data_path must end with generated_data\n",
    "        data_path = data_path + \"generated_data/\"\n",
    "\n",
    "        for gen_name in gen_expts:\n",
    "\n",
    "            bm_root = data_path + \"chm{}/{}/\".format(chm,gen_name)\n",
    "            snp, bal, dat = np.array(bm_root.split(\"/\"))[-7:-4]\n",
    "            \n",
    "            if snp == \"full\":\n",
    "                W = 1000\n",
    "            elif snp== \"ukb\":\n",
    "                W = 30\n",
    "            \n",
    "            metric_path = bm_root + \"benchmark_results.pkl\"\n",
    "            if local_metric is not None:\n",
    "                metric_path = metric_path.replace(\"arvindsk\", local_metric)\n",
    "\n",
    "            gens = gen_expts[gen_name]\n",
    "\n",
    "            print(\"-\"*100)\n",
    "            print(\"Experiment details\")\n",
    "            print(\"Dataset used: {}\".format(data_path))\n",
    "            print(\"Generations used: {}\".format(gens))\n",
    "            print(\"Metrics will come up at: {}\".format(metric_path))\n",
    "\n",
    "            metrics = bm_train(base, smooth, \n",
    "                               bm_root, data_path, \n",
    "                               gens, chm=chm,\n",
    "                               W=W, \n",
    "                               load_base=True, load_smooth=True, \n",
    "                               eval=False,\n",
    "                               models_exist=models_exist,\n",
    "                               verbose=True)\n",
    "\n",
    "            save_dict(metrics, metric_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = [\"lgb\", \"xgb\", \"logreg\"]\n",
    "smooth = [\"xgb\", \"crf\", \"cnv\"]\n",
    "\n",
    "# here we run 3 base, 3 smooth, 2 datasets, 3 populations, 2 balance\n",
    "\n",
    "chm = 20\n",
    "gen_expts = {\n",
    "    \"all\" : [0,2,4,8,16,24,32,48,64,72,100]\n",
    "}\n",
    "run_bm(base, smooth, chm, gen_expts, models_exist=False, local_metric=\"arvindsk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = [\"rf\",\"lgb\", \"xgb\", \"logreg\"]\n",
    "smooth = [\"xgb\", \"crf\", \"cnv\"]\n",
    "for gen_name in gen_expts:\n",
    "    for data_path in datasets_benchmark:\n",
    "        bm_root = data_path + \"generated_data/chm{}/{}/\".format(chm,gen_name)\n",
    "        print(bm_root)\n",
    "        metric_path = bm_root + \"benchmark_results.pkl\"\n",
    "        M = load_dict(metric_path)\n",
    "        accs = plt_metric(base ,smooth, M, \"val_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; \n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "def get_metric(base,smooth,Metrics,metric):\n",
    "    M = {}\n",
    "    for i, b in enumerate(base):\n",
    "        M[b] = {}\n",
    "        for j, s in enumerate(smooth):\n",
    "            M[b][s] = Metrics[b+\"_\"+s][metric]\n",
    "            \n",
    "    return pd.DataFrame(M)\n",
    "\n",
    "\n",
    "def plt_metric(base,smooth,Metrics,metric,vminmax=(None,None),cbar=True):\n",
    "    \n",
    "    if metric == \"gen_performance\":\n",
    "        cmap = { 0:'k', 1:'b',  2:'y', 3:'g'}\n",
    "        lmap = { 0:'-', 1:'--', 2:':', 3:'-.' }\n",
    "        v_accs = get_metric(base, smooth, Metrics, \"val_acc\")\n",
    "        for i, b in enumerate(base):\n",
    "            for j, s in enumerate(smooth):\n",
    "                m_name = b + \"_\" + s\n",
    "                data = Metrics[m_name][metric] \n",
    "                plt.plot(data[\"gens\"], data[\"accs\"], linestyle=lmap[i%len(lmap)], color=cmap[j%len(cmap)],\n",
    "                         label= m_name + \" (\" + str(v_accs[b][j]) + \"%)\")\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1, 1), loc='upper left') \n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Accuracy (%)\")\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        data = get_metric(base,smooth,Metrics,metric)\n",
    "        sns.heatmap(data, annot=True, fmt=\".2f\",vmin=vminmax[0], vmax=vminmax[1], cbar=cbar)\n",
    "        plt.xlabel(\"base model\")\n",
    "        plt.ylabel(\"smoother\")\n",
    "        plt.show()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [\"rf\", \"lgb\", \"xgb\", \"logreg\"]\n",
    "smooth = [\"cnv\", \"xgb\", \"crf\"]\n",
    "\n",
    "cols = [\"base\", \"smooth\",\"data\",\"gen\",\"bal\",\"snp\",\"val_acc\"]\n",
    "ACC = [] # (b, s, data, gen, bal, ukb, acc)\n",
    "all_accs = np.zeros( (len(base), len(smooth), len(gen_expts), len(datasets_benchmark)) )\n",
    "for g, gen_name in enumerate(gen_expts):\n",
    "    for d, data_path in enumerate(datasets_benchmark):\n",
    "        bm_root = data_path + \"generated_data/chm{}/{}/\".format(chm,gen_name)\n",
    "        metric_path = bm_root + \"benchmark_results.pkl\"\n",
    "        M = load_dict(metric_path)\n",
    "        \n",
    "        v_accs = get_metric(base, smooth, M, \"val_acc\")\n",
    "        \n",
    "        dat = np.array(bm_root.split(\"/\"))[-5]\n",
    "        bal = np.array(bm_root.split(\"/\"))[-6]\n",
    "        ukb = np.array(bm_root.split(\"/\"))[-7]\n",
    "        for b in base:\n",
    "            for s in smooth:\n",
    "                ACC += [(b,s,dat,gen_name,bal,ukb,v_accs[b][s])]\n",
    "DF = pd.DataFrame(ACC, columns=cols)\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (LogReg) X (XGB, CRF) performing best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.boxplot(column=[\"val_acc\"], by=[\"snp\",\"base\", \"smooth\"], figsize=(16,8), rot=\"45\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.boxplot(column=[\"val_acc\"], by=[\"snp\", \"base\", \"smooth\"], figsize=(16,8), rot=\"45\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_best_models = DF[ \n",
    "    ~(DF.base.isin([\"rf\", \"lgb\"])) &\n",
    "    (DF.smooth != \"cnv\")\n",
    "]\n",
    "DF_best_models.boxplot(column=[\"val_acc\"], by=[\"base\", \"smooth\"], figsize=(16,8), rot=\"45\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance not affacting much but still a bit\n",
    "we want to repeat with fixed validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.boxplot(column=[\"val_acc\"], by=[\"data\", \"bal\"], figsize=(16,8), rot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## same pattern using only best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_best_models.boxplot(column=[\"val_acc\"], by=[\"data\", \"bal\"], figsize=(16,8), rot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracies similar for high generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_lathi = DF[ \n",
    "    (DF.base != \"rf\") &\n",
    "    (DF.smooth != \"cnv\") &\n",
    "    (DF.gen==\"high\") ]\n",
    "DF_lathi.boxplot(column=[\"val_acc\"], by=[\"data\", \"snp\", \"smooth\"], figsize=(16,8), rot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/\"\n",
    "base = [\"xgb\", \"logreg\"]\n",
    "smooth = [\"xgb\", \"crf\"]\n",
    "gen_name = \"high\"\n",
    "bm_root = data_path + \"generated_data/chm{}/{}/\".format(chm,gen_name)\n",
    "metric_path = bm_root + \"benchmark_results.pkl\"\n",
    "M = load_dict(metric_path)\n",
    "out = plt_metric(base ,smooth, M, \"gen_performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note! acc > 90% for gen 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
