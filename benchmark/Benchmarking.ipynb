{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Benchmarking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with a single expt\n",
    "\n",
    "base = [\"xgb\"]\n",
    "smooth= [\"xgb\"]\n",
    "# data_path must contain simulation_output folder\n",
    "data_path = \"/home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/generated_data/\"\n",
    "chm = 20\n",
    "bm_root = data_path + \"chm{}/\".format(chm)\n",
    "\n",
    "gens = [0,2,4] #todo\n",
    "\n",
    "\n",
    "metrics = bm_train(base, smooth, \n",
    "                   bm_root, data_path, \n",
    "                   gens, chm=chm,\n",
    "                   W=1000, \n",
    "                   load_base=True, load_smooth=True, \n",
    "                   eval=True, \n",
    "                   verbose=True)\n",
    "\n",
    "metric_path = data_path + \"chm{}/\".format(chm) + \"benchmark_results.pkl\"\n",
    "save_dict(metrics, metric_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_test = load_dict(metric_path)\n",
    "load_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_benchmark = [\n",
    "\n",
    "# full set of full-bal_admix\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/latino/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/five/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/bal_admix/seven/\",\n",
    "\n",
    "# full set of full-unbal_unbal\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/latino/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/five/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/unbal_unbal/seven/\",\n",
    "\n",
    "# full-bal_unbal only for seven and latino - this way we complete a latino sweep to compare different balances\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/bal_unbal/seven/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/bal_unbal/latino/\",\n",
    "# full-bal_bal only for latino - seems like a nice expt\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/full/bal_bal/latino/\",\n",
    "\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/latino/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/five/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_admix/seven/\",\n",
    "    \n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/latino/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/five/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/unbal_unbal/seven/\",\n",
    "\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_unbal/seven/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_unbal/latino/\",\n",
    "\"/home/arvindsk/xgmix_expts/benchmark_data/ukb/bal_bal/latino/\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [\"rf\",\"lgb\", \"xgb\", \"logreg\"]\n",
    "smooth = [\"xgb\", \"crf\", \"cnv\"]\n",
    "chm = 20\n",
    "\n",
    "gens_expts = {\"low\":[0,2,4,8,16,24],\"high\":[0,32,48,64,72,100],\"all\":[0,2,4,8,16,24,32,48,64,72,100]}\n",
    "\n",
    "\n",
    "for data_path in datasets_benchmark:\n",
    "    \n",
    "    # data_path must end with generated_data\n",
    "    \n",
    "    for gen_name in gen_expts:\n",
    "        \n",
    "        data_path = data_path + \"/generated_data/\"\n",
    "        bm_root = data_path + \"/chm{}/{}/\".format(chm,gen_name)\n",
    "        # this bm_root will be created by bm_train function\n",
    "        gens = gen_expts[gen_name]\n",
    "        \n",
    "        print(\"Experiment details/n\")\n",
    "        print(\"Dataset used: {}\".format(data_path))\n",
    "        print(\"Generations used: {}\".format(gens))\n",
    "        print(\"Metrics will come up at: {}\".format(bm_root))\n",
    "\n",
    "        metrics = bm_train(base, smooth, \n",
    "                           bm_root, data_path, \n",
    "                           gens, chm=chm,\n",
    "                           W=1000, \n",
    "                           load_base=True, load_smooth=True, \n",
    "                           eval=True, \n",
    "                           verbose=True)\n",
    "\n",
    "        metric_path = bm_root + \"/benchmark_results.pkl\"\n",
    "        save_dict(metrics, metric_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
